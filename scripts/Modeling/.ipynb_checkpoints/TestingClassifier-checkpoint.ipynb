{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiamingqu/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../DataProcessing/tone_content_genre_cleaned.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7005, 59)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to 0/1 labels\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "labels_list = []\n",
    "for index,rows in df.iterrows():\n",
    "    x = df.loc[index,\"tone\"].split(\",\")\n",
    "    labels_list.append(x)\n",
    "\n",
    "labels = mlb.fit_transform(labels_list)\n",
    "\n",
    "# check shape\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7005, 332)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to 0/1 genres\n",
    "genres_list = []\n",
    "for index, rows in df.iterrows():\n",
    "    x = df.loc[index, \"genre\"].split(\",\")\n",
    "    genres_list.append(x)\n",
    "\n",
    "genres = mlb.fit_transform(genres_list)\n",
    "\n",
    "genres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "df_train_corpus = pd.DataFrame(df.iloc[:5136,0])\n",
    "df_test_corpus =  pd.DataFrame(df.iloc[5136:,0])\n",
    "df_train_genre = genres[:5136]\n",
    "df_test_genre = genres[5136:]\n",
    "df_train_label = labels[:5136]\n",
    "df_test_label = labels[5136:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5136, 1)\n",
      "(1869, 1)\n",
      "(5136, 332)\n",
      "(1869, 332)\n",
      "(5136, 59)\n",
      "(1869, 59)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print(df_train_corpus.shape)\n",
    "print(df_test_corpus.shape)\n",
    "print(df_train_genre.shape)\n",
    "print(df_test_genre.shape)\n",
    "print(df_train_label.shape)\n",
    "print(df_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text\n",
    "def CleanText(raw_comment):\n",
    "    # 1. lower case\n",
    "    new_comment = raw_comment.lower()\n",
    "    # 2. remove punctuation\n",
    "    new_comment = re.sub(r\"[^\\w\\s]\", \"\", new_comment)\n",
    "    return new_comment\n",
    "\n",
    "#Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "#Stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the tf-idf vectorizer\n",
    "tfidf_vectorizer = joblib.load(\"../saved_models/TfidfVectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiamingqu/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# load the classifier\n",
    "BinaryClassifier = joblib.load(\"../saved_models/BinaryClassifierWithGenre.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecision(true_label,predicted_prob, K):\n",
    "    '''\n",
    "    Get the precision@K\n",
    "    '''\n",
    "    return sum([i[1] for i in sorted(zip(predicted_prob, true_label), key=lambda x: x[0], reverse=True)[:K]])/float(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecall(true_label,predicted_prob, K):\n",
    "    '''\n",
    "    Get the recall@K\n",
    "    '''\n",
    "    return sum([i[1] for i in sorted(zip(predicted_prob, true_label), key=lambda x: x[0], reverse=True)[:K]])/float(len(true_label[true_label == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignValues(predicted_labels_prob):\n",
    "    '''\n",
    "    This function takes an array of probabilities and assig 1 to the highest 2 values\n",
    "    '''\n",
    "    \n",
    "    # find the largest index\n",
    "    first_index = np.argmax(predicted_labels_prob)\n",
    "    # assign it to 0\n",
    "    predicted_labels_prob[first_index] = 0\n",
    "    \n",
    "    # find the second largest index\n",
    "    second_index = np.argmax(predicted_labels_prob)\n",
    "    # assign it to 0\n",
    "    predicted_labels_prob[second_index] = 0\n",
    "    \n",
    "    # assign 0 to 1\n",
    "    predicted_labels_prob[predicted_labels_prob == 0] = 1\n",
    "    \n",
    "    # assign others to 0\n",
    "    predicted_labels_prob[predicted_labels_prob != 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewAccuracy(true_labels, predicted_labels):\n",
    "    '''\n",
    "    Based on Jaccard Similarity\n",
    "    '''\n",
    "    return round(jaccard_similarity_score(true_labels, predicted_labels),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageAccuracy(true_labels, predicted_labels):\n",
    "    \n",
    "    '''\n",
    "    This function gives the average accuracy for *each classifier*\n",
    "    '''\n",
    "    \n",
    "    if(true_labels.shape[1] != predicted_labels.shape[1]) or (true_labels.shape[0] != predicted_labels.shape[0]):\n",
    "        return \"Wrong Shape\"\n",
    "    \n",
    "    NSample = true_labels.shape[0]\n",
    "    NLabel = true_labels.shape[1]\n",
    "    \n",
    "    avg_accuracy = 0\n",
    "    \n",
    "    for i in range(0, NLabel):\n",
    "        N = 0\n",
    "        for j in range(0, NSample):\n",
    "            if true_labels[j][i] == predicted_labels[j][i]:\n",
    "                N += 1\n",
    "        print(\"Accuracy for classifier {} is {}\".format(i, N/NSample))\n",
    "        \n",
    "        avg_accuracy += N/NSample\n",
    "        \n",
    "    print(\"Average accuracy for {} classifiers is {}\".format(NLabel, avg_accuracy/NLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tones = []\n",
    "predicted_tones = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, rows in df_test_corpus.iterrows():\n",
    "    \n",
    "    # for each book\n",
    "    true_tone = df_test_label[index - 5136]\n",
    "    reviews = df_test_corpus.loc[index,\"content\"].split(\"-----\")\n",
    "    \n",
    "    # store predicted tones on reviews\n",
    "    predict_tone = np.zeros(59)\n",
    "    \n",
    "    # predict on each review\n",
    "    for review in reviews:\n",
    "        # clean the review text\n",
    "        review_cleaned = stemming(removeStopWords(CleanText(review)))\n",
    "        \n",
    "        # generate the tfidf_vector\n",
    "        tfidf_vector = tfidf_vectorizer.transform([review_cleaned])\n",
    "        \n",
    "        # predict in the classifier\n",
    "        review_predict_tone = BinaryClassifier.predict_proba(tfidf_vector)\n",
    "        \n",
    "        predict_tone += review_predict_tone.toarray()[0]\n",
    "        \n",
    "    true_tones.append(true_tone)\n",
    "    \n",
    "        \n",
    "    # calculate the mean (actually it is the same with sum)\n",
    "    # predict_tone = predict_tone/len(reviews)\n",
    "    \n",
    "    assignValues(predict_tone)\n",
    "    \n",
    "    predicted_tones.append(predict_tone)\n",
    "    \n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to array\n",
    "true_tones = np.array(true_tones)\n",
    "predicted_tones = np.array(predicted_tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04678473941471466"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hemming loss\n",
    "hamming_loss(true_tones, predicted_tones) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classifier 0 is 0.8710540395933655\n",
      "Accuracy for classifier 1 is 0.9662921348314607\n",
      "Accuracy for classifier 2 is 0.550561797752809\n",
      "Accuracy for classifier 3 is 0.9892990904226859\n",
      "Accuracy for classifier 4 is 0.9695024077046549\n",
      "Accuracy for classifier 5 is 0.9951845906902087\n",
      "Accuracy for classifier 6 is 0.9973247726056714\n",
      "Accuracy for classifier 7 is 0.9785981808453719\n",
      "Accuracy for classifier 8 is 0.9721776350989834\n",
      "Accuracy for classifier 9 is 0.9721776350989834\n",
      "Accuracy for classifier 10 is 0.9646869983948636\n",
      "Accuracy for classifier 11 is 0.9844836811128946\n",
      "Accuracy for classifier 12 is 0.9898341359015517\n",
      "Accuracy for classifier 13 is 0.9646869983948636\n",
      "Accuracy for classifier 14 is 0.9604066345639379\n",
      "Accuracy for classifier 15 is 0.9978598180845372\n",
      "Accuracy for classifier 16 is 0.994649545211343\n",
      "Accuracy for classifier 17 is 0.9823434991974318\n",
      "Accuracy for classifier 18 is 0.9818084537185661\n",
      "Accuracy for classifier 19 is 0.9759229534510433\n",
      "Accuracy for classifier 20 is 0.9957196361690743\n",
      "Accuracy for classifier 21 is 0.9866238630283574\n",
      "Accuracy for classifier 22 is 0.9957196361690743\n",
      "Accuracy for classifier 23 is 0.9898341359015517\n",
      "Accuracy for classifier 24 is 0.9941144997324772\n",
      "Accuracy for classifier 25 is 0.985553772070626\n",
      "Accuracy for classifier 26 is 0.9646869983948636\n",
      "Accuracy for classifier 27 is 0.9882289994649546\n",
      "Accuracy for classifier 28 is 0.9983948635634029\n",
      "Accuracy for classifier 29 is 0.9892990904226859\n",
      "Accuracy for classifier 30 is 0.9828785446762975\n",
      "Accuracy for classifier 31 is 0.9935794542536116\n",
      "Accuracy for classifier 32 is 0.985553772070626\n",
      "Accuracy for classifier 33 is 0.7158908507223114\n",
      "Accuracy for classifier 34 is 0.994649545211343\n",
      "Accuracy for classifier 35 is 0.9973247726056714\n",
      "Accuracy for classifier 36 is 0.9887640449438202\n",
      "Accuracy for classifier 37 is 0.9625468164794008\n",
      "Accuracy for classifier 38 is 0.9994649545211343\n",
      "Accuracy for classifier 39 is 0.9903691813804173\n",
      "Accuracy for classifier 40 is 0.9957196361690743\n",
      "Accuracy for classifier 41 is 0.9641519529159979\n",
      "Accuracy for classifier 42 is 0.9705724986623863\n",
      "Accuracy for classifier 43 is 0.9994649545211343\n",
      "Accuracy for classifier 44 is 0.9780631353665061\n",
      "Accuracy for classifier 45 is 0.9930444087747459\n",
      "Accuracy for classifier 46 is 0.9951845906902087\n",
      "Accuracy for classifier 47 is 0.990904226859283\n",
      "Accuracy for classifier 48 is 0.9903691813804173\n",
      "Accuracy for classifier 49 is 0.980203317281969\n",
      "Accuracy for classifier 50 is 0.9957196361690743\n",
      "Accuracy for classifier 51 is 0.9529159978598181\n",
      "Accuracy for classifier 52 is 0.9464954521134297\n",
      "Accuracy for classifier 53 is 0.15409309791332262\n",
      "Accuracy for classifier 54 is 0.9785981808453719\n",
      "Accuracy for classifier 55 is 0.9052969502407705\n",
      "Accuracy for classifier 56 is 0.9432851792402355\n",
      "Accuracy for classifier 57 is 0.9727126805778491\n",
      "Accuracy for classifier 58 is 0.9748528624933119\n",
      "Average accuracy for 59 classifiers is 0.9532152605852857\n"
     ]
    }
   ],
   "source": [
    "AverageAccuracy(true_tones,predicted_tones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "0.130669995838538\n",
      "0.8015694667380061\n"
     ]
    }
   ],
   "source": [
    "avg_precision = 0\n",
    "avg_recall = 0\n",
    "count = 0\n",
    "\n",
    "for index, rows in df_test_corpus.iterrows():\n",
    "    \n",
    "    # for each book\n",
    "    true_tone = df_test_label[index - 5136]\n",
    "    reviews = df_test_corpus.loc[index,\"content\"].split(\"-----\")\n",
    "    genre = df_test_genre[index - 5136]\n",
    "    \n",
    "    # store predicted tones on reviews\n",
    "    predict_tone = np.zeros(59)\n",
    "    \n",
    "    # predict on each review\n",
    "    for review in reviews:\n",
    "        \n",
    "        # clean the review text\n",
    "        review_cleaned = stemming(removeStopWords(CleanText(review)))\n",
    "        \n",
    "        # generate the tfidf_vector\n",
    "        tfidf_vector = tfidf_vectorizer.transform([review_cleaned])\n",
    "        \n",
    "        # convert tdidf vector to numpy array\n",
    "        tfidf_vector = tfidf_vector.toarray()[0]\n",
    "        \n",
    "        # add into a new feature vector\n",
    "        feature_vector = np.concatenate([tfidf_vector, genre])\n",
    "        \n",
    "        # reshape\n",
    "        feature_vector = feature_vector.reshape(1, 29684)\n",
    "        \n",
    "        # predict in the classifier\n",
    "        review_predict_tone = BinaryClassifier.predict_proba(feature_vector)\n",
    "        \n",
    "        predict_tone += review_predict_tone.toarray()[0]\n",
    "            \n",
    "    # calculate the mean (actually it is the same with sum)\n",
    "    predict_tone = predict_tone/len(reviews)\n",
    "    \n",
    "    avg_precision += getPrecision(true_tone, predict_tone, 3)\n",
    "    avg_recall += getRecall(true_tone, predict_tone, 3)\n",
    "    \n",
    "    if count % 200 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    \n",
    "print(avg_precision/df_test_corpus.shape[0])\n",
    "print(avg_recall/df_test_corpus.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
