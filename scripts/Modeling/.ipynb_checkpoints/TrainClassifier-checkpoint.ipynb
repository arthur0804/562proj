{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../DataProcessing/tone_content_genre_cleaned.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7005, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 0/1 labels\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "labels_list = []\n",
    "for index,rows in df.iterrows():\n",
    "    x = df.loc[index,\"tone\"].split(\",\")\n",
    "    labels_list.append(x)\n",
    "\n",
    "labels = mlb.fit_transform(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 0/1 genres\n",
    "genres_list = []\n",
    "for index, rows in df.iterrows():\n",
    "    x = df.loc[index, \"genre\"].split(\",\")\n",
    "    genres_list.append(x)\n",
    "\n",
    "genres = mlb.fit_transform(genres_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "df_train_corpus = pd.DataFrame(df.iloc[:5136, 0])\n",
    "df_test_corpus = pd.DataFrame(df.iloc[5136:, 0])\n",
    "df_train_genre = genres[:5136]\n",
    "df_test_genre = genres[5136:]\n",
    "df_train_label = labels[:5136]\n",
    "df_test_label = labels[5136:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the reviews and add into the expanded df\n",
    "\n",
    "df_train_corpus_expanded = pd.DataFrame(columns=['reviews'])\n",
    "df_train_label_expanded = []\n",
    "df_train_genre_expanded = []\n",
    "\n",
    "for index, rows in df_train_corpus.iterrows():\n",
    "\n",
    "    reviews = df_train_corpus.iloc[index, 0]\n",
    "    tones = df_train_label[index]\n",
    "    genres = df_train_genre[index]\n",
    "\n",
    "    for review in reviews.split(\"-----\"):\n",
    "        df_train_corpus_expanded.loc[df_train_corpus_expanded.shape[0]] = review\n",
    "        df_train_label_expanded.append(tones)\n",
    "        df_train_genre_expanded.append(genres)\n",
    "\n",
    "df_train_label_expanded = np.array(df_train_label_expanded)\n",
    "df_train_genre_expanded = np.array(df_train_genre_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12003, 1)\n",
      "(12003, 59)\n",
      "(12003, 332)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_corpus_expanded.shape)\n",
    "print(df_train_label_expanded.shape)\n",
    "print(df_train_genre_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_corpus_expanded contains 12003 reviews\n",
    "# 332 genres as high-level-features\n",
    "# 59 tones to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text\n",
    "def CleanText(raw_comment):\n",
    "    # 1. lower case\n",
    "    new_comment = raw_comment.lower()\n",
    "    # 2. remove punctuation\n",
    "    new_comment = re.sub(r\"[^\\w\\s]\", \"\", new_comment)\n",
    "    return new_comment\n",
    "\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "\n",
    "\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "\n",
    "# Stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_train_corpus_expanded.iterrows():\n",
    "    raw_comment = df_train_corpus_expanded.loc[index, 'reviews']\n",
    "    df_train_corpus_expanded.loc[index, 'reviews'] = stemming(removeStopWords(CleanText(raw_comment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the tf-idf representation for review training corpus\n",
    "list_all_words = []\n",
    "for i in df_train_corpus_expanded.reviews:\n",
    "    words = word_tokenize(i)\n",
    "    for word in words:\n",
    "        list_all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(input=list_all_words, lowercase=True, min_df=2, ngram_range=(1, 1))\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(df_train_corpus_expanded.reviews)\n",
    "\n",
    "# concatenate tfidf features with genre features\n",
    "tfidf_matrix_train = tfidf_matrix_train.toarray()\n",
    "training_features = np.concatenate((tfidf_matrix_train, df_train_genre_expanded), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12003, 29684)\n",
      "(12003, 59)\n"
     ]
    }
   ],
   "source": [
    "print(training_features.shape)\n",
    "print(df_train_label_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_models/TfidfVectorizer.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save tf-idf vectorizer\n",
    "joblib.dump(tfidf_vectorizer, '../saved_models/TfidfVectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This takes a lot of computinng resource the train.\n",
    "### I trained it on the UNC longleaf research compting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "BinaryClassifier = BinaryRelevance(classifier=LogisticRegression())\n",
    "BinaryClassifier.fit(training_features, df_train_label_expanded)\n",
    "joblib.dump(BinaryClassifier, '../saved_models/BinaryClassifierWithGenre.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
